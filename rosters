import pandas as pd
import re
import urllib
from time import sleep
#divisions are numbered
south_teams = [2588, 2589, 2590, 2591, 2592, 2593, 2594]
north_teams = [2581, 2582, 2583, 2584, 2585, 2586, 2587]

#Find URLs for all teams
def build_team_urls():
    # Open the division webpage and extract the names of each team available.
    for division in south_teams{
        url_string = 'http://www.wchlonline.com/division/'+ str(division)
        f = urllib.request.urlopen(url_string)
        teams_source = f.read().decode('utf-8')
        teams = dict(re.findall("www\.wchlonline\.com/team/(\w+)/(.+?)\",", teams_source))
        # Using the names of the rosters, create the urls of each roster
        roster_urls = []
        for key in teams.keys():
            # each roster webpage follows this general pattern.
            roster_urls.append('http://www.wchlonline.com/team/' + key + '/' + teams[key])
            teams[key] = str(teams[key])
    return dict(zip(teams.values(), roster_urls))

pd.read_html("https://www.wchlonline.com/team/32248/roster")[0].iloc[:,1:]

import requests
from bs4 import BeautifulSoup


url = "https://www.wchlonline.com/team/32248/roster"
soup = BeautifulSoup(requests.get(url).content, "html.parser")
data = []
for row in soup.select("#DataTable tbody tr"):
    data.append({
            "Player": row.a.text,
            "Team": row.select_one("td>a").text,
            "Position": row.select("td.text-left")[2].text.strip(),
            "Points Matchday": row.select("td.text-right")[0].text.strip(),
            "Market value": row.select("td.text-right")[1].text.strip(),
            "Appearances": row.select("td.text-right")[2].text.strip(),
            "Avrg. points": row.select("td.text-right")[3].text.strip(),
            "Total points": row.select("td.text-right")[4].text.strip()
        }
    )
data
print(data)
